{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vf7Ne1I35myu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb8d8cb9-c779-4cc5-b16f-2694c435273d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.5-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.1.5\n"
          ]
        }
      ],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyngrok\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "0a75zqh4uzv1",
        "outputId": "470aa07f-fd3c-42ee-e60d-d10e353fd895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7a0a157924d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://97feeec7590b:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (1,\"abc\",\"aef\",\"ahi\",\"akl\",123),\n",
        "    (2,\"qbc\",\"qef\",\"qhi\",\"qkl\",124),\n",
        "    (3,\"wbc\",\"wef\",\"whi\",\"wkl\",125),\n",
        "]\n",
        "columns_schema = [\"id\",\"firstname\",\"lastname\",\"country\",\"state\",\"salary\"]\n",
        "df = spark.createDataFrame(data = data, schema = columns_schema)"
      ],
      "metadata": {
        "id": "1XSgLypVu5qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeOfNZXtu_bb",
        "outputId": "93c27850-4b51-4f63-90a1-4ba73d34b627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+--------+-------+-----+------+\n",
            "| id|firstname|lastname|country|state|salary|\n",
            "+---+---------+--------+-------+-----+------+\n",
            "|  1|      abc|     aef|    ahi|  akl|   123|\n",
            "|  2|      qbc|     qef|    qhi|  qkl|   124|\n",
            "|  3|      wbc|     wef|    whi|  wkl|   125|\n",
            "+---+---------+--------+-------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAyG8umEvHpx",
        "outputId": "2adc2cac-1d99-4906-849b-956451f31729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: bigint, firstname: string, lastname: string, country: string, state: string, salary: bigint]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "schema = StructType(\n",
        "    [\n",
        "      StructField('id',IntegerType()),\n",
        "      StructField('first_name',StringType()),\n",
        "      StructField('last_name',StringType()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "df1 = spark.read.csv(\"sample_data/names.csv\", header = True , schema = schema)\n",
        "df1.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPze2q-nvM1v",
        "outputId": "62757cce-37f8-48cd-f071-55a4011c2982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+---------+\n",
            "| id|first_name|last_name|\n",
            "+---+----------+---------+\n",
            "|613|   Lucinda|    Tench|\n",
            "|181|   Yevette|   Ebanks|\n",
            "|963| Ekaterina|    Hamly|\n",
            "|140|    Sherye| Paxforde|\n",
            "|800|     Gayla|     Girk|\n",
            "|985|    Dannie|   Berzin|\n",
            "|931|       Cal|  Benitti|\n",
            "|975|   Hilario|   Warbys|\n",
            "|607|      Geri| Creeghan|\n",
            "|777|      Vita|   Haldin|\n",
            "+---+----------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = spark.read.options(delimiter='|', inferschema=True, header=True).csv(\"sample_data/MOCK.csv\")\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFi_qiIYvfRV",
        "outputId": "0e5b08b6-6047-4ef2-ef83-bd32b2cc33c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+----+-----+\n",
            "|CountryName|CountryCode|Year|Value|\n",
            "+-----------+-----------+----+-----+\n",
            "|     Russia|         RU|  92|   60|\n",
            "|   Colombia|         CO|  83|   87|\n",
            "|      China|         CN|  33|   13|\n",
            "|     France|         FR|  47|   27|\n",
            "|  Argentina|         AR|  36|   98|\n",
            "|     Brazil|         BR|  54|   48|\n",
            "|     Poland|         PL|  25|   98|\n",
            "|  Indonesia|         ID|  97|  100|\n",
            "|     Sweden|         SE|  15|   96|\n",
            "|     Sweden|         SE|  51|   84|\n",
            "|     Zambia|         ZM|  12|  100|\n",
            "|      China|         CN|  69|   49|\n",
            "|  Indonesia|         ID|  96|   38|\n",
            "|     Norway|         NO|  85|   93|\n",
            "|     Mexico|         MX|  78|   86|\n",
            "|     Brazil|         BR|  21|   42|\n",
            "|     Russia|         RU|  96|   83|\n",
            "|     Brazil|         BR|  31|   80|\n",
            "|     Brazil|         BR|  52|   53|\n",
            "|      China|         CN|  94|   80|\n",
            "+-----------+-----------+----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = spark.read.csv(\"sample_data/MOCK.csv\")\n",
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrO7LoENvvVe",
        "outputId": "21289c50-a7ce-4367-f10d-f36329e6805a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                 _c0|\n",
            "+--------------------+\n",
            "|CountryName|Count...|\n",
            "|     Russia|RU|92|60|\n",
            "|   Colombia|CO|83|87|\n",
            "|      China|CN|33|13|\n",
            "|     France|FR|47|27|\n",
            "|  Argentina|AR|36|98|\n",
            "|     Brazil|BR|54|48|\n",
            "|     Poland|PL|25|98|\n",
            "| Indonesia|ID|97|100|\n",
            "|     Sweden|SE|15|96|\n",
            "|     Sweden|SE|51|84|\n",
            "|    Zambia|ZM|12|100|\n",
            "|      China|CN|69|49|\n",
            "|  Indonesia|ID|96|38|\n",
            "|     Norway|NO|85|93|\n",
            "|     Mexico|MX|78|86|\n",
            "|     Brazil|BR|21|42|\n",
            "|     Russia|RU|96|83|\n",
            "|     Brazil|BR|31|80|\n",
            "|     Brazil|BR|52|53|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pW7rcFnwHMp",
        "outputId": "b5ceefe6-7e11-4152-d9f3-729880467c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- CountryName: string (nullable = true)\n",
            " |-- CountryCode: string (nullable = true)\n",
            " |-- Year: integer (nullable = true)\n",
            " |-- Value: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP0KNEBgwVEb",
        "outputId": "f68aabab-37e7-443d-acf4-a463e1a143cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CountryName', 'CountryCode', 'Year', 'Value']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndz9wpS7wYDT",
        "outputId": "78fde89d-cddd-4b7c-cb53-e8ddd10bc62a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggGdKMWnwbFu",
        "outputId": "e9969362-ea1a-426f-a1e1-ce97f28a803e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+----+-----+\n",
            "|CountryName|CountryCode|Year|Value|\n",
            "+-----------+-----------+----+-----+\n",
            "|     Russia|         RU|  92|   60|\n",
            "|   Colombia|         CO|  83|   87|\n",
            "+-----------+-----------+----+-----+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = df2.withColumnRenamed('CountryName', 'Country Name').withColumnRenamed('CountryCode', 'Country Code')\n",
        "df4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JR9_HUpwnFw",
        "outputId": "3a8d85fb-f3be-47da-e36f-4afd8db31a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------+----+-----+\n",
            "|Country Name|Country Code|Year|Value|\n",
            "+------------+------------+----+-----+\n",
            "|      Russia|          RU|  92|   60|\n",
            "|    Colombia|          CO|  83|   87|\n",
            "|       China|          CN|  33|   13|\n",
            "|      France|          FR|  47|   27|\n",
            "|   Argentina|          AR|  36|   98|\n",
            "|      Brazil|          BR|  54|   48|\n",
            "|      Poland|          PL|  25|   98|\n",
            "|   Indonesia|          ID|  97|  100|\n",
            "|      Sweden|          SE|  15|   96|\n",
            "|      Sweden|          SE|  51|   84|\n",
            "|      Zambia|          ZM|  12|  100|\n",
            "|       China|          CN|  69|   49|\n",
            "|   Indonesia|          ID|  96|   38|\n",
            "|      Norway|          NO|  85|   93|\n",
            "|      Mexico|          MX|  78|   86|\n",
            "|      Brazil|          BR|  21|   42|\n",
            "|      Russia|          RU|  96|   83|\n",
            "|      Brazil|          BR|  31|   80|\n",
            "|      Brazil|          BR|  52|   53|\n",
            "|       China|          CN|  94|   80|\n",
            "+------------+------------+----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as psf\n",
        "df4.filter(psf.col('Country Name')=='Russia').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgyCcp91xJya",
        "outputId": "ca45ec6d-f91f-49a4-8875-782857f5bec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------+----+-----+\n",
            "|Country Name|Country Code|Year|Value|\n",
            "+------------+------------+----+-----+\n",
            "|      Russia|          RU|  92|   60|\n",
            "|      Russia|          RU|  96|   83|\n",
            "|      Russia|          RU|  31|    4|\n",
            "|      Russia|          RU|   2|   72|\n",
            "|      Russia|          RU|  25|    1|\n",
            "|      Russia|          RU|  49|   22|\n",
            "|      Russia|          RU|  48|   11|\n",
            "|      Russia|          RU|  81|   13|\n",
            "|      Russia|          RU|  95|   44|\n",
            "|      Russia|          RU|  12|   77|\n",
            "|      Russia|          RU|  50|   54|\n",
            "|      Russia|          RU|  11|   54|\n",
            "|      Russia|          RU|  72|   12|\n",
            "|      Russia|          RU|  72|   49|\n",
            "|      Russia|          RU|  95|  100|\n",
            "|      Russia|          RU|  70|   69|\n",
            "|      Russia|          RU|  14|   45|\n",
            "|      Russia|          RU|   2|    9|\n",
            "|      Russia|          RU|  87|   85|\n",
            "|      Russia|          RU|  96|   58|\n",
            "+------------+------------+----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4.orderBy('Value').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohhmh519xvqa",
        "outputId": "e58e5b2d-c03a-443e-e4dd-33ba634613cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------+----+-----+\n",
            "|        Country Name|Country Code|Year|Value|\n",
            "+--------------------+------------+----+-----+\n",
            "|           Indonesia|          ID|  79|    1|\n",
            "|               China|          CN|  47|    1|\n",
            "|           Indonesia|          ID|  74|    1|\n",
            "|           Indonesia|          ID|  79|    1|\n",
            "|           Indonesia|          ID|  17|    1|\n",
            "|              Russia|          RU|  25|    1|\n",
            "|Palestinian Terri...|          PS|  75|    1|\n",
            "|               Yemen|          YE|  69|    1|\n",
            "|               China|          CN|  31|    1|\n",
            "|             Iceland|          IS|  31|    1|\n",
            "|              Serbia|          RS|  65|    1|\n",
            "|             Nigeria|          NG|  62|    1|\n",
            "|               China|          CN|  37|    2|\n",
            "|               China|          CN|  57|    2|\n",
            "|           Indonesia|          ID|  42|    2|\n",
            "|      United Kingdom|          GB|  67|    2|\n",
            "|               China|          CN|  94|    2|\n",
            "|               China|          CN|   8|    2|\n",
            "|         Philippines|          PH|  85|    2|\n",
            "|           Argentina|          AR|  60|    2|\n",
            "+--------------------+------------+----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4.select('Country Code').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw43PaJtyImi",
        "outputId": "020a80a6-d6e6-4ff1-c058-6f4d28a6c34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|Country Code|\n",
            "+------------+\n",
            "|          RU|\n",
            "|          CO|\n",
            "|          CN|\n",
            "|          FR|\n",
            "|          AR|\n",
            "|          BR|\n",
            "|          PL|\n",
            "|          ID|\n",
            "|          SE|\n",
            "|          SE|\n",
            "|          ZM|\n",
            "|          CN|\n",
            "|          ID|\n",
            "|          NO|\n",
            "|          MX|\n",
            "|          BR|\n",
            "|          RU|\n",
            "|          BR|\n",
            "|          BR|\n",
            "|          CN|\n",
            "+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4.groupBy('Country Name').agg(psf.max('Value')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wbz10PRI0faR",
        "outputId": "4c6967b9-929f-4281-dc80-4e49fbf158d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+\n",
            "|Country Name|max(Value)|\n",
            "+------------+----------+\n",
            "|        Chad|         4|\n",
            "|      Russia|       100|\n",
            "|    Paraguay|        84|\n",
            "|       Yemen|        74|\n",
            "|     Senegal|        43|\n",
            "|      Sweden|        98|\n",
            "| Philippines|       100|\n",
            "|    Malaysia|        85|\n",
            "|   Singapore|        73|\n",
            "|      Malawi|        98|\n",
            "|        Iraq|        55|\n",
            "|     Germany|        86|\n",
            "| Afghanistan|        97|\n",
            "|    Cambodia|         4|\n",
            "| Ivory Coast|        78|\n",
            "|      Rwanda|        29|\n",
            "|       Sudan|        32|\n",
            "|       Palau|        96|\n",
            "|      France|        97|\n",
            "|      Greece|        94|\n",
            "+------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from pyspark.sql.functions import col, from_unixtime, unix_timestamp\n",
        "with open('dummy.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"id\",\"Name\",\"Address\",\"Date\"])\n",
        "    writer.writerow([1,\"ABC\", \"D/O New Delhi\",\"2023-01-01 10:22\"])\n",
        "    writer.writerow([2,\"DEF\",\"C\\O Tarun123 New Delhi\",\"2023-01-01 12:22\"])\n",
        "    writer.writerow([3,\"GHI\", \"C//O Tarun ₹ New Delhi\",\"2023-01-02 18:23\"])\n",
        "\n",
        "df5 = spark.read.options( inferschema=True, header=True).csv(\"dummy.csv\")\n",
        "\n",
        "exp = '^(D/O|C\\\\\\\\O) [A-Za-z0-9 ]+$'\n",
        "\n",
        "df5.filter(col(\"Address\").rlike(exp)).show(truncate=False)\n",
        "\n",
        "df6 = df5.withColumn(\"Date\", from_unixtime(unix_timestamp(col(\"Date\"), \"yyyy-MM-dd HH:mm\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
        "df6.show()"
      ],
      "metadata": {
        "id": "jD7j-YZqV7l-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91d402df-c09b-4c59-e7e8-471b38d76562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+----------------------+----------------+\n",
            "|id |Name|Address               |Date            |\n",
            "+---+----+----------------------+----------------+\n",
            "|1  |ABC |D/O New Delhi         |2023-01-01 10:22|\n",
            "|2  |DEF |C\\O Tarun123 New Delhi|2023-01-01 12:22|\n",
            "+---+----+----------------------+----------------+\n",
            "\n",
            "+---+----+--------------------+-------------------+\n",
            "| id|Name|             Address|               Date|\n",
            "+---+----+--------------------+-------------------+\n",
            "|  1| ABC|       D/O New Delhi|2023-01-01 10:22:00|\n",
            "|  2| DEF|C\\O Tarun123 New ...|2023-01-01 12:22:00|\n",
            "|  3| GHI|C//O Tarun ₹ New ...|2023-01-02 18:23:00|\n",
            "+---+----+--------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#AryamaanBorah\n",
        "import csv\n",
        "from pyspark.sql.functions import col, from_unixtime, unix_timestamp\n",
        "with open('dummy.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"id\",\"Name\",\"Address\",\"Date\"])\n",
        "    writer.writerow([1,\"ABC\", \"D/O New Delhi\",\"2023-01-01 10:22\"])\n",
        "    writer.writerow([2,\"DEF\",\"C\\O Tarun123 New Delhi\",\"2023-01-01 12:22\"])\n",
        "    writer.writerow([3,\"GHI\", \"C//O Tarun ₹ New Delhi\",\"2023-01-02 18:23\"])\n",
        "\n",
        "df5 = spark.read.options( inferschema=True, header=True).csv(\"dummy.csv\")\n",
        "\n",
        "exp = '^(D/O|C\\\\\\\\O) [A-Za-z0-9 ]+$'\n",
        "\n",
        "df5.filter(col(\"Address\").rlike(exp)).show(truncate=False)\n",
        "\n",
        "df6 = df5.withColumn(\"Date\", from_unixtime(unix_timestamp(col(\"Date\"), \"yyyy-MM-dd HH:mm\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
        "df6.show()"
      ],
      "metadata": {
        "id": "o39lUKfCLfeM",
        "outputId": "8a36ba4f-15fa-44c1-84c1-d8f7fb31451b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+----------------------+----------------+\n",
            "|id |Name|Address               |Date            |\n",
            "+---+----+----------------------+----------------+\n",
            "|1  |ABC |D/O New Delhi         |2023-01-01 10:22|\n",
            "|2  |DEF |C\\O Tarun123 New Delhi|2023-01-01 12:22|\n",
            "+---+----+----------------------+----------------+\n",
            "\n",
            "+---+----+--------------------+-------------------+\n",
            "| id|Name|             Address|               Date|\n",
            "+---+----+--------------------+-------------------+\n",
            "|  1| ABC|       D/O New Delhi|2023-01-01 10:22:00|\n",
            "|  2| DEF|C\\O Tarun123 New ...|2023-01-01 12:22:00|\n",
            "|  3| GHI|C//O Tarun ₹ New ...|2023-01-02 18:23:00|\n",
            "+---+----+--------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "\n",
        "def func():\n",
        "  try:\n",
        "    data = [\n",
        "    (1,\"abc\",\"aef\",\"ahi\",\"akl\",123),\n",
        "    (2,\"qbc\",\"qef\",\"qhi\",\"qkl\",124),\n",
        "    (3,\"wbc\",\"wef\",\"whi\",\"wkl\",125),\n",
        "    ]\n",
        "    columns_schema = [\"id\",\"firstname\",\"lastname\",\"country\",\"state\",\"salary\"]\n",
        "    df = spark.createDataFrame(data = data, schema = columns_schema)\n",
        "    df.show()\n",
        "    logging.info(\"Successfully Created\")\n",
        "  except Exception as e:\n",
        "    logging.error(\"an error has occured\")\n",
        "  finally:\n",
        "    spark.stop\n",
        "\n",
        "func()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPMl17BHsBBp",
        "outputId": "93c5eaad-9150-4590-d7a4-12445df39b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Successfully Created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+--------+-------+-----+------+\n",
            "| id|firstname|lastname|country|state|salary|\n",
            "+---+---------+--------+-------+-----+------+\n",
            "|  1|      abc|     aef|    ahi|  akl|   123|\n",
            "|  2|      qbc|     qef|    qhi|  qkl|   124|\n",
            "|  3|      wbc|     wef|    whi|  wkl|   125|\n",
            "+---+---------+--------+-------+-----+------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}