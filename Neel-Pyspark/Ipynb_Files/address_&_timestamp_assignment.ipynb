{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "bOl8HYqQAybo",
        "outputId": "a24f88f3-5132-4199-8f6e-4128612e6333"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f8b87fea110>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://a8793536dd2f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "      SparkSession\n",
        "        .builder\n",
        "        .appName(\"SparkApp\")\n",
        "        .master(\"local[5]\")\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "gUEszTDRYcGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ad_df = spark.read.format(\"CSV\").option(\"header\",True).option(\"truncate\",False).load(\"/content/Book1.csv\")\n",
        "ad_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv9_-6AmBmRU",
        "outputId": "ab2c1f4b-19b3-485f-f49f-34f9c6bb08bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|             address|\n",
            "+--------------------+\n",
            "|       D/O New Delhi|\n",
            "|C\\O Tarun123 New ...|\n",
            "|C//O Tarun ₹ New ...|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "reg = r'[^\\x00-\\x7F]'\n",
        "\n",
        "\n",
        "ad_df.withColumn('special_address',regexp_extract('address',reg,0)).filter(\"special_address = ''\" ).select(\"address\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYcDxYUcB0Fs",
        "outputId": "18bf5716-22c7-4890-bc3b-b6e81d112bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|             address|\n",
            "+--------------------+\n",
            "|       D/O New Delhi|\n",
            "|C\\O Tarun123 New ...|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = spark.read.format(\"CSV\").option(\"header\",True).option(\"truncate\",False).load(\"/content/50-contacts.csv\")"
      ],
      "metadata": {
        "id": "99zVks3sB2In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df.withColumn('special_address',regexp_extract('address',reg,0)).filter(\"special_address = ''\" ).select(\"address\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw2_rY5vB450",
        "outputId": "3aab4167-0657-4f94-c38c-40bc41675d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|             address|\n",
            "+--------------------+\n",
            "| C\\B Blue Ridge Blvd|\n",
            "|8 W Cerritos Ave #54|\n",
            "|        C//O Main St|\n",
            "|        34 Center St|\n",
            "|        3 Mcauley Dr|\n",
            "|           7 Eads St|\n",
            "|    7 W Jackson Blvd|\n",
            "|    5 Boston Ave #88|\n",
            "|228 Runamuck Pl #...|\n",
            "|   2371 ?Jerrold Ave|\n",
            "|  37275 St  Rt 17m M|\n",
            "|    25 E 75th St #69|\n",
            "|98 Connecticut Av...|\n",
            "|    56 E Morehead St|\n",
            "| 73 State Road 434 E|\n",
            "| 69734 E Carrillo St|\n",
            "|322 New? Horizon ...|\n",
            "|    1 State Route 27|\n",
            "| 394 Manchester Blvd|\n",
            "|         6 S 33rd St|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "date_df = spark.read.format(\"CSV\").option(\"header\",True).option(\"truncate\",False).load(\"/content/datefile.csv\")\n",
        "date_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwNNvD_HCRE5",
        "outputId": "93893a0f-0491-477f-e4c5-b7cd950a744d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------------+\n",
            "|       start_time|         end_time|\n",
            "+-----------------+-----------------+\n",
            "| 2023-01-01 10:22| 2023-01-01 12:30|\n",
            "| 2023-02-15 18:45| 2023-02-16 08:00|\n",
            "| 2023-03-30 07:10| 2023-02-16 18:00|\n",
            "+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = date_df.withColumn('time_col', to_date(col(\"start_time\"), \"yyyy-MM-dd HH:mm\"))\n",
        "temp2 = temp.withColumn(\"Start_timestamp\",col(\"time_col\").cast(\"timestamp\"))\n"
      ],
      "metadata": {
        "id": "4aueEOgSCV-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(temp2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkknzb3XCcwt",
        "outputId": "1454f7b7-27f9-4813-b7b6-f7a892e23a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame[start_time: string,  end_time: string, time_col: date, Start_timestamp: timestamp]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# after tranformation my dataframe contain a new column which is the required timestamp column\n",
        "# but im not able to show it, i tired it many times but every time. Im still trying to figure it out"
      ],
      "metadata": {
        "id": "Vx_EeekMCgly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.getLogger().setLevel(logging.INFO)"
      ],
      "metadata": {
        "id": "11n0_AxNsWrP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func():\n",
        "  ad_df = spark.read.format(\"CSV\").option(\"header\",True).option(\"truncate\",False).load(\"/content/Book1.csv\")\n",
        "  ad_df.show()\n",
        "  logging.info(\"successfully created\")\n",
        "\n",
        "func()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swJuV1CWsg1G",
        "outputId": "d1f1b168-a696-49da-c4be-b8e81f944c00"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:successfully created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|             address|\n",
            "+--------------------+\n",
            "|       D/O New Delhi|\n",
            "|C\\O Tarun123 New ...|\n",
            "|C//O Tarun ₹ New ...|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_function():\n",
        "    try:\n",
        "        # Your PySpark code here\n",
        "        logging.info(\"Operation successful\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "my_function()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fxUe_sUtNQ4",
        "outputId": "27534a1a-d6be-4a04-b7b0-4e94313d9661"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Operation successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_function()"
      ],
      "metadata": {
        "id": "J-14Xm1PtifP"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}