{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "STTnjwLt4wJN",
        "outputId": "3bbb4474-98c2-4e80-b812-50b8d2e728f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ce84c2b9360>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://004d1d6d8119:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "spark = SparkSession.builder.appName(\"AddressFilter\").getOrCreate()\n",
        "\n",
        "# creating dataframe\n",
        "data = [\n",
        "(\"D/O New Delhi\",),\n",
        "(\"C\\\\O Tarun123 New Delhi\",),\n",
        "(\"C// tarun â‚¹ New Delhi\",),\n",
        "(\"C// tarun % New Delhi\",)]\n"
      ],
      "metadata": {
        "id": "uEBYUn474xUn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"Address\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "r_pattern = \"^[A-Za-z0-9 /\\\\\\\\]*New Delhi$\""
      ],
      "metadata": {
        "id": "OQPHGe33IYWI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = df.filter(col(\"Address\").rlike(r_pattern))\n",
        "final_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N6CKQ1gIZhI",
        "outputId": "f9de0518-2446-44b6-d12c-abb2f5bc0b15"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------+\n",
            "|Address               |\n",
            "+----------------------+\n",
            "|D/O New Delhi         |\n",
            "|C\\O Tarun123 New Delhi|\n",
            "+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YpV-AbceI_ED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2nd Question"
      ],
      "metadata": {
        "id": "lId8Y48EI_92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, to_timestamp, date_format\n",
        "spark = SparkSession.builder.appName(\"TimestampConversion\").getOrCreate()\n",
        "\n",
        "#  DataFrame\n",
        "data = [(\"2023-01-01 10:22\",)]\n",
        "columns = [\"Start\"]\n",
        "df = spark.createDataFrame(data, columns)"
      ],
      "metadata": {
        "id": "IE0xFQ145up7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the column to a proper timestamp format\n",
        "df = df.withColumn(\"Start\", to_timestamp(col(\"Start\"), \"yyyy-MM-dd HH:mm\"))\n",
        "\n",
        "# Format the timestamp to \"YYYY-MM-DD HH:MM:SS\" with seconds set to 00\n",
        "df = df.withColumn(\"Start\", date_format(col(\"Start\"), \"yyyy-MM-dd HH:mm:ss\"))"
      ],
      "metadata": {
        "id": "xK_as1dBIxxx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the result\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSIhjoiJIx1S",
        "outputId": "86b7b6ed-f780-47f7-f24d-333c6dd5b358"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "|Start              |\n",
            "+-------------------+\n",
            "|2023-01-01 10:22:00|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "6hBVKhU0DiuY",
        "outputId": "241cbd07-4429-4823-f618-8e2c637858cc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.printSchema of DataFrame[Start: string]>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame.printSchema</b><br/>def printSchema()</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/spark-3.1.1-bin-hadoop3.2/python/pyspark/sql/dataframe.py</a>Prints out the schema in the tree format.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; df.printSchema()\n",
              "root\n",
              " |-- age: integer (nullable = true)\n",
              " |-- name: string (nullable = true)\n",
              "&lt;BLANKLINE&gt;</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 282);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oc9JJGCWI8SD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}