{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "FR0COVcVU9Dv",
        "outputId": "ff6b4b5e-7c8f-4928-decf-7b78ad3a66cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fd650142650>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://db176c8e440d:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rypIBvjGUoT2",
        "outputId": "2897ba8c-14c2-4141-9647-bcd3dfc25d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------+\n",
            "|Address               |\n",
            "+----------------------+\n",
            "|D/O New Delhi         |\n",
            "|C\\O Tarun123 New Delhi|\n",
            "+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#1\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import BooleanType\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Pattern Matching\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "(\"D/O New Delhi\",),\n",
        "(\"C\\\\O Tarun123 New Delhi\",),\n",
        "(\"C/D/ Kanisk  New Delhi $\",)]\n",
        "\n",
        "columns = [\"Address\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "regex = \"^[A-Za-z0-9 /\\\\\\\\]*New Delhi$\"\n",
        "\n",
        "import re\n",
        "\n",
        "def matchPattern(add):\n",
        "  if re.match(regex,str(add)):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "matchPatternUDF = udf(matchPattern, BooleanType())\n",
        "\n",
        "df = df.filter(matchPatternUDF(col(\"Address\")))\n",
        "\n",
        "df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2.\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, to_timestamp, date_format\n",
        "spark = SparkSession.builder.appName(\"timeconvert\").getOrCreate()\n",
        "\n",
        "data = [(\"2023-01-01 10:22\",)]\n",
        "columns = [\"Time\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()\n",
        "\n",
        "df = df.withColumn(\"Time\", to_timestamp(col(\"Time\"), \"yyyy-MM-dd HH:mm\"))\n",
        "df.show()\n",
        "\n",
        "df = df.withColumn(\"Time\", date_format(col(\"Time\"), \"MM-yyyy-dd HH:mm:ss\"))\n",
        "\n",
        "df.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utMLak_lU1OJ",
        "outputId": "f029f201-c59d-4201-f5ed-58b4a168c0bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|            Time|\n",
            "+----------------+\n",
            "|2023-01-01 10:22|\n",
            "+----------------+\n",
            "\n",
            "+-------------------+\n",
            "|               Time|\n",
            "+-------------------+\n",
            "|2023-01-01 10:22:00|\n",
            "+-------------------+\n",
            "\n",
            "+-------------------+\n",
            "|Time               |\n",
            "+-------------------+\n",
            "|01-2023-01 10:22:00|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "360aXXmuZ0db"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}